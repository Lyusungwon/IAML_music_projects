{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import gfile\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import pickle\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from librosa import display\n",
    "from collections import Counter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_features(tids):\n",
    "    successful_tids = []\n",
    "    successful_features = []\n",
    "    for tid in tids:\n",
    "        try:\n",
    "            filepath = get_audio_path('dataset/audio', tid)\n",
    "\n",
    "            try:\n",
    "                ### do not change here !\n",
    "                x, sr = librosa.load(filepath, sr=44100, mono=True, duration=20)\n",
    "                x = x.tolist()\n",
    "\n",
    "                new_x = []\n",
    "                while len(new_x) < 44100 * 20:\n",
    "                    new_x.extend(x)\n",
    "                new_x = new_x[:44100 * 20]\n",
    "                x = np.array(new_x)\n",
    "                ###\n",
    "                front_x = x[:2205]\n",
    "                end_x = x[41895:]\n",
    "                x = np.append(front_x, x)\n",
    "                x = np.append(x, end_x)\n",
    "\n",
    "                hop_length=512\n",
    "                timeseries_length = 18\n",
    "                for i in range(200):\n",
    "                    data = np.zeros((40, timeseries_length), dtype=np.float64)\n",
    "                    mini_x = x[i*4410:i*4410 + 8820]\n",
    "                    stft = np.abs(librosa.stft(mini_x, n_fft=2048, hop_length=hop_length))\n",
    "                    mel = librosa.feature.melspectrogram(sr=sr, S=stft ** 2)\n",
    "                    del stft\n",
    "                    mfcc = librosa.feature.mfcc(S=librosa.power_to_db(mel), n_mfcc=20)\n",
    "                    spectral_center = librosa.feature.spectral_centroid(mini_x, sr=sr, hop_length=hop_length)\n",
    "                    chroma = librosa.feature.chroma_stft(mini_x, sr=sr, hop_length=hop_length)\n",
    "                    spectral_contrast = librosa.feature.spectral_contrast(mini_x, sr=sr, hop_length=hop_length)\n",
    "                    data[0:20, :] = mfcc\n",
    "                    data[20:21, :] = spectral_center\n",
    "                    data[21:33, :] = chroma\n",
    "                    data[33:40, :] = spectral_contrast\n",
    "                    successful_tids.append(tid)\n",
    "                    successful_features.append(data)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(filepath, e)\n",
    "\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print('{}: {}'.format(tid, repr(e)))\n",
    "\n",
    "    return successful_tids, successful_features\n",
    "\n",
    "def feature_examples(tid):\n",
    "    # example of various librosa features\n",
    "    # please check [https://librosa.github.io/librosa/feature.html]\n",
    "    threshold = 1278900\n",
    "    try:\n",
    "        filepath = get_audio_path('dataset/audio', tid)\n",
    "        ### do not change here !\n",
    "        x, sr = librosa.load(filepath, sr=44100, mono=True, duration=20)\n",
    "        x = x.tolist()\n",
    "        origin_length = len(x)\n",
    "\n",
    "        new_x = []\n",
    "        while len(new_x) < 44100 * 20:\n",
    "            new_x.extend(x)\n",
    "        new_x = new_x[:44100 * 20]\n",
    "        x = np.array(new_x)\n",
    "        ###\n",
    "\n",
    "        # zero_crossing_rate\n",
    "        # returns (1,t)\n",
    "        f = librosa.feature.zero_crossing_rate(x, frame_length=2048, hop_length=512)\n",
    "\n",
    "\n",
    "        cqt = np.abs(librosa.cqt(x, sr=sr, hop_length=512, bins_per_octave=12,\n",
    "                                 n_bins=7 * 12, tuning=None))\n",
    "        assert cqt.shape[0] == 7 * 12\n",
    "        assert np.ceil(len(x) / 512) <= cqt.shape[1] <= np.ceil(len(x) / 512) + 1\n",
    "\n",
    "        # chroma_cqt\n",
    "        # returns (n_chroma, t)\n",
    "        f = librosa.feature.chroma_cqt(C=cqt, n_chroma=12, n_octaves=7)\n",
    "\n",
    "        # chroma_cqt\n",
    "        # returns (n_chroma, t)\n",
    "        f = librosa.feature.chroma_cens(C=cqt, n_chroma=12, n_octaves=7)\n",
    "\n",
    "        del cqt\n",
    "        stft = np.abs(librosa.stft(x, n_fft=2048, hop_length=512))\n",
    "        assert stft.shape[0] == 1 + 2048 // 2\n",
    "        assert np.ceil(len(x) / 512) <= stft.shape[1] <= np.ceil(len(x) / 512) + 1\n",
    "        del x\n",
    "\n",
    "        # chroma_stft\n",
    "        # returns (n_chroma, t)\n",
    "        f = librosa.feature.chroma_stft(S=stft ** 2, n_chroma=12)\n",
    "\n",
    "        # rmse\n",
    "        # returns (1,t)\n",
    "        f = librosa.feature.rmse(S=stft)\n",
    "\n",
    "        # spectral_centroid\n",
    "        # returns (1,t)\n",
    "        f = librosa.feature.spectral_centroid(S=stft)\n",
    "\n",
    "        # spectral_bandwidth\n",
    "        # returns (1,t)\n",
    "        f = librosa.feature.spectral_bandwidth(S=stft)\n",
    "\n",
    "        # spectral_contrast\n",
    "        # returns (n_bands+1, t)\n",
    "        f = librosa.feature.spectral_contrast(S=stft, n_bands=6)\n",
    "\n",
    "        # spectral_rolloff\n",
    "        # returns (1,t)\n",
    "        f = librosa.feature.spectral_rolloff(S=stft)\n",
    "\n",
    "        # mfcc\n",
    "        # returns (n_mfcc, t)\n",
    "        mel = librosa.feature.melspectrogram(sr=sr, S=stft ** 2)\n",
    "        del stft\n",
    "        f = librosa.feature.mfcc(S=librosa.power_to_db(mel), n_mfcc=20)\n",
    "\n",
    "    except Exception as e:\n",
    "        print('{}: {}'.format(tid, repr(e)))\n",
    "        return tid, 0\n",
    "\n",
    "\n",
    "def get_audio_path(audio_dir, track_id):\n",
    "    return os.path.join(audio_dir, track_id + '.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fixed\n",
    "meta_path = 'dataset/audio_list.csv'\n",
    "label_path = 'dataset/labels.pkl'\n",
    "val_set_number = 0\n",
    "\n",
    "metadata_df = pd.read_csv(meta_path)\n",
    "train_meta_df = metadata_df[metadata_df['set'] != val_set_number]\n",
    "val_meta_df = metadata_df[metadata_df['set'] == val_set_number]\n",
    "# metadata_df = metadata_df.sample(frac=1).reset_index(drop=True)\n",
    "train_track_ids = train_meta_df['FileName'].values\n",
    "val_track_ids = val_meta_df['FileName'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyusungwon/anaconda3/envs/tensorflow/lib/python3.6/site-packages/librosa/core/pitch.py:145: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  warnings.warn('Trying to estimate tuning from empty frequency set.')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-743fb43853b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_track_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_track_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mXd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mXd_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mXd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXd_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-a2a3fcf7a575>\u001b[0m in \u001b[0;36mcompute_features\u001b[0;34m(tids)\u001b[0m\n\u001b[1;32m     32\u001b[0m                     \u001b[0mmfcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower_to_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mfcc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0mspectral_center\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspectral_centroid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhop_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                     \u001b[0mchroma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchroma_stft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhop_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                     \u001b[0mspectral_contrast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspectral_contrast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhop_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmfcc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/librosa/feature/spectral.py\u001b[0m in \u001b[0;36mchroma_stft\u001b[0;34m(y, sr, S, norm, n_fft, hop_length, tuning, **kwargs)\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'A440'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m440.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuning\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_chroma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m     \u001b[0mchromafb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchroma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m     \u001b[0;31m# Compute raw chroma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/librosa/filters.py\u001b[0m in \u001b[0;36mchroma\u001b[0;34m(sr, n_fft, n_chroma, A440, ctroct, octwidth, norm, base_c)\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;31m# add on fixed offset of 10*n_chroma to ensure all values passed to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;31m# rem are positive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m     \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremainder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn_chroma2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn_chroma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_chroma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_chroma2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# Gaussian bumps - 2*D to make them narrower\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ids, features = compute_features(train_track_ids)\n",
    "val_ids, val_features = compute_features(val_track_ids)\n",
    "Xd = np.array(features)\n",
    "Xd_val = np.array(val_features)\n",
    "Xd.shape, Xd_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xd = pickle.load(open('mix.pkl', 'rb'))\n",
    "Xd_val = pickle.load(open('mix_val.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11600, 8), (5800, 8))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pickle.load(open(label_path, 'rb'))\n",
    "\n",
    "def get_labels(name_list):\n",
    "    # get labels from label dictionary\n",
    "    # [[list of hihats],[list of kicks], [list of snares],\n",
    "    #   [list of hihats],[list of kicks], [list of snares]],...\n",
    "#     print(\"name_list\", name_list)\n",
    "    label = []\n",
    "    for x in name_list:\n",
    "        label.append(labels[x])\n",
    "    label = np.array(label)\n",
    "    return label\n",
    "\n",
    "def to_eight(onehot):\n",
    "    hihat = onehot[:,0,:].flatten()\n",
    "    kick = onehot[:,1,:].flatten()\n",
    "    snare = onehot[:,2,:].flatten()\n",
    "    n = onehot.shape[0]*onehot.shape[2]\n",
    "    yd = np.zeros((n, 8))\n",
    "    for i in range(n):\n",
    "        if hihat[i] == 1 and kick[i] != 1 and snare[i] != 1:\n",
    "            yd[i,1] = 1\n",
    "        elif hihat[i] != 1 and kick[i] == 1 and snare[i] != 1:\n",
    "            yd[i,2] = 1\n",
    "        elif hihat[i] != 1 and kick[i] != 1 and snare[i] == 1:\n",
    "            yd[i,3] = 1        \n",
    "        elif hihat[i] == 1 and kick[i] == 1 and snare[i] != 1:\n",
    "            yd[i,4] = 1\n",
    "        elif hihat[i] == 1 and kick[i] != 1 and snare[i] == 1:\n",
    "            yd[i,5] = 1\n",
    "        elif hihat[i] != 1 and kick[i] == 1 and snare[i] == 1:\n",
    "            yd[i,6] = 1\n",
    "        elif hihat[i] == 1 and kick[i] == 1 and snare[i] == 1:\n",
    "            yd[i,7] = 1     \n",
    "        else:\n",
    "            yd[i,0] = 1    \n",
    "    return yd\n",
    "\n",
    "yd = to_eight(np.array(get_labels(train_track_ids)))\n",
    "yd_val = to_eight(np.array(get_labels(val_track_ids)))\n",
    "yd.shape, yd_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('mix.pkl', 'wb') as mixf:\n",
    "    pickle.dump(Xd, mixf, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('y.pkl', 'wb') as yf:\n",
    "    pickle.dump(yd, yf, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('mix_val.pkl', 'wb') as mix_valf:\n",
    "    pickle.dump(Xd_val, mix_valf, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('y_val.pkl', 'wb') as y_valf:\n",
    "    pickle.dump(yd_val, y_valf, protocol=pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model for training and validation\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "n_input = 40 * 18\n",
    "n_classs = 8\n",
    "image_height = 40\n",
    "image_width = 18\n",
    "# fully-connected layer property\n",
    "hidden1 = 1024\n",
    "hidden2 = 1024\n",
    "dropout_rate = 0.5\n",
    "# convolutional layer property\n",
    "conv_size = 3\n",
    "n_filter1 = 64\n",
    "n_filter2 = 128\n",
    "n_filter3 = 256\n",
    "# pooling layer property\n",
    "pool_size = 2\n",
    "# Placeholder and variables\n",
    "# TODO : declare placeholder and variables\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, image_height, image_width])\n",
    "y = tf.placeholder(tf.int64, [None, n_classs])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "# Build model\n",
    "# TODO : build your model here\n",
    "# Model\n",
    "def from_eight(y_preds):\n",
    "    hihat = [0] * len(y_preds)\n",
    "    kick = [0] * len(y_preds)\n",
    "    snare = [0] * len(y_preds)\n",
    "    for i in range(len(y_preds)):\n",
    "        if y_preds[i, 1] == 1:\n",
    "            hihat[i] = 1\n",
    "        elif y_preds[i, 2] == 1:\n",
    "            kick[i] = 1\n",
    "        elif y_preds[i, 3] == 1:\n",
    "            snare[i] = 1\n",
    "        elif y_preds[i, 4] == 1:\n",
    "            hihat[i] = 1\n",
    "            kick[i] = 1\n",
    "        elif y_preds[i, 5] == 1:\n",
    "            hihat[i] = 1\n",
    "            snare[i] = 1\n",
    "        elif y_preds[i, 6] == 1:\n",
    "            kick[i] = 1\n",
    "            snare[i] = 1\n",
    "        elif y_preds[i, 7] == 1:\n",
    "            hihat[i] = 1\n",
    "            kick[i] = 1\n",
    "            snare[i] = 1\n",
    "    return [hihat, kick, snare]\n",
    "\n",
    "def onehot(y):\n",
    "    yd = np.zeros_like(y)\n",
    "    for n, i in enumerate(np.argmax(y, 1)):\n",
    "        yd[n,i] = 1\n",
    "    return yd        \n",
    "\n",
    "def calculate_average_F1_score(pred_lists, label_lists):\n",
    "    # calculate average F1 score (hihat, kick, snare)\n",
    "    # shape of each list is 3*200\n",
    "    avg_f1_score = 0\n",
    "    for pred_list, label_list in zip(pred_lists, label_lists):\n",
    "        counts = Counter(zip(pred_list, label_list))\n",
    "        tp = counts[1,1]\n",
    "        fp = counts[1,0]\n",
    "        fn = counts[0,1]\n",
    "        try:\n",
    "            precision = tp / (tp+fp)\n",
    "        except ZeroDivisionError:\n",
    "            precision = 0\n",
    "\n",
    "        try:\n",
    "            recall = tp / (fn + tp)\n",
    "        except ZeroDivisionError:\n",
    "            recall = 0\n",
    "\n",
    "        try:\n",
    "            f1 = 2*(precision*recall / (precision+recall))\n",
    "        except ZeroDivisionError:\n",
    "            f1 = 0\n",
    "        avg_f1_score+=f1\n",
    "\n",
    "#         print(precision, recall, f1)\n",
    "\n",
    "    avg_f1_score /= 3\n",
    "    return avg_f1_score\n",
    "\n",
    "def model(X,y,is_training):\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(1e-6)\n",
    "    activation = tf.nn.elu\n",
    "    init = tf.contrib.layers.xavier_initializer()\n",
    "    \n",
    "    x_reshaped = tf.reshape(X, [-1, image_height, image_width, 1])\n",
    "    c11 = tf.layers.conv2d(x_reshaped, n_filter1, conv_size, 1, \"same\", activation = activation, kernel_initializer = init, kernel_regularizer = regularizer)\n",
    "    c12 = tf.layers.conv2d(c11, n_filter1, conv_size, 1, \"same\", activation = activation, kernel_initializer = init, kernel_regularizer = regularizer)\n",
    "    mp1 = tf.layers.max_pooling2d(c11, pool_size, 2,  \"same\")\n",
    "    c21 = tf.layers.conv2d(mp1, n_filter2, conv_size, 1, \"same\", activation = activation, kernel_initializer = init, kernel_regularizer = regularizer)\n",
    "    c22 = tf.layers.conv2d(c21, n_filter2, conv_size, 1, \"same\", activation = activation, kernel_initializer = init, kernel_regularizer = regularizer)\n",
    "    mp2 = tf.layers.max_pooling2d(c21, pool_size, 2,  \"same\")\n",
    "    c3 = tf.layers.conv2d(mp2, 1, 1, 1, \"same\", activation = activation, kernel_initializer = init, kernel_regularizer = regularizer)\n",
    "    if is_training is not None:\n",
    "        c3 = tf.nn.dropout(c3, dropout_rate) * dropout_rate\n",
    "    flat = tf.reshape(c3, [-1, 50])\n",
    "\n",
    "    w_fc1 = tf.get_variable(\"W_fc1\", shape=[n_input + 50, hidden1], initializer=init, regularizer=regularizer)\n",
    "    b_fc1 = tf.get_variable(\"b_fc1\", shape=[hidden1], initializer=init, regularizer=regularizer)\n",
    "    w_fc2 = tf.get_variable(\"W_fc2\", shape=[hidden1, hidden2], initializer=init, regularizer=regularizer)\n",
    "    b_fc2 = tf.get_variable(\"b_fc2\", shape=[hidden2], initializer=init, regularizer=regularizer)\n",
    "    w_out = tf.get_variable(\"W_out\", shape=[hidden2, n_classs], initializer=init, regularizer=regularizer)\n",
    "    b_out = tf.get_variable(\"b_out\", shape=[n_classs], initializer=init, regularizer=regularizer)\n",
    "    \n",
    "    x_reshaped2 = tf.reshape(X, [-1, n_input])\n",
    "    x_concat = tf.concat([x_reshaped2, flat], 1)\n",
    "    z1 = tf.matmul(x_concat, w_fc1) + b_fc1\n",
    "    a1 = tf.contrib.layers.batch_norm(z1)\n",
    "    fc1 = tf.nn.elu(a1)\n",
    "    if is_training is not None:\n",
    "        fc1 = tf.nn.dropout(fc1, dropout_rate) * dropout_rate\n",
    "    z2 = tf.matmul(fc1, w_fc2) + b_fc2\n",
    "    a2 = tf.contrib.layers.batch_norm(z2)\n",
    "    fc2 = tf.nn.elu(a2)\n",
    "    if is_training is not None:\n",
    "        fc2 = tf.nn.dropout(fc2, dropout_rate) * dropout_rate   \n",
    "    y_out = tf.matmul(fc2, w_out) + b_out\n",
    "    return y_out\n",
    "\n",
    "y_out = model(X,y,is_training)\n",
    "\n",
    "# Loss and optimizer\n",
    "# TODO : declare loss and optimizer operation\n",
    "\n",
    "total_loss = tf.losses.softmax_cross_entropy(y,logits=y_out) \n",
    "mean_loss = tf.reduce_mean(total_loss)\n",
    "optimizer = tf.train.AdamOptimizer(1e-5) \n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(extra_update_ops):\n",
    "    train_step = optimizer.minimize(mean_loss)    \n",
    "correct_prediction = tf.equal(tf.argmax(y_out,1), tf.argmax(y,1))\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "best_loss = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoint/concat_1024_mix_18_elu\n",
      "Validation loss, Overall loss = 0.302, accuracy of 0.932 and f1 score of 0.933\n"
     ]
    }
   ],
   "source": [
    "# properties\n",
    "# General\n",
    "# TODO : declare additional properties\n",
    "# not fixed (change or add property as you like)\n",
    "batch_size = 5800\n",
    "epoch_num = 10000\n",
    "print_every = 100\n",
    "\n",
    "# fixed\n",
    "# True if you want to train, False if you already trained your model\n",
    "# TODO : IMPORTANT !!! Please change it to False when you submit your code\n",
    "is_train_mode = False\n",
    "train_validation = True\n",
    "validation = True\n",
    "# TODO : IMPORTANT !!! Please specify the path where your best model is saved\n",
    "# example : checkpoint/run-0925-0348\n",
    "checkpoint_path = 'checkpoint/concat_1024_mix_18_elu'\n",
    "\n",
    "# X, y, mean_loss,correct_prediction,train_step, accuracy = my_model(lr = 2e-4, rl = 1e-4,  is_training= is_train_mode)\n",
    "#load data\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, checkpoint_path)\t\t\t\n",
    "    if is_train_mode:\n",
    "        variables = [mean_loss,correct_prediction, y_out, train_step]\n",
    "        iter_cnt = 0\n",
    "        best_f1 = 0\n",
    "        for e in range(epoch_num):                   \n",
    "            train_indicies = np.arange(Xd.shape[0])\n",
    "            np.random.shuffle(train_indicies)\n",
    "            correct = 0\n",
    "            losses = []\n",
    "            f1_scores = []\n",
    "            for i in range(int(math.ceil(Xd.shape[0]/batch_size))):\n",
    "                start_idx = (i*batch_size)%Xd.shape[0]\n",
    "                idx = train_indicies[start_idx:start_idx+batch_size]\n",
    "                feed_dict = {X: Xd[idx,:],\n",
    "                             y: yd[idx] }\n",
    "                actual_batch_size = yd[idx].shape[0]\n",
    "                loss, corr, y_outs, _ = sess.run(variables,feed_dict=feed_dict)\n",
    "                losses.append(loss*actual_batch_size)\n",
    "                correct += np.sum(corr)\n",
    "                f1_score = calculate_average_F1_score(from_eight(onehot(y_outs)), from_eight(yd[idx]))\n",
    "                f1_scores.append(f1_score*actual_batch_size)\n",
    "                if is_train_mode and (iter_cnt % print_every) == 0:\n",
    "                    print(\"Iteration {0}: with minibatch training loss = {1:.3g}, accuracy of {2:.2g}, and f1 score of {3:.2g}\"\\\n",
    "                          .format(iter_cnt,loss,np.sum(corr)/actual_batch_size, f1_score))\n",
    "                iter_cnt += 1\n",
    "            total_correct = correct/Xd.shape[0]\n",
    "            total_loss = np.sum(losses)/Xd.shape[0]\n",
    "            total_f1 = np.sum(f1_scores)/Xd.shape[0]\n",
    "            print(\"Epoch {2}, Overall loss = {0:.3g}, accuracy of {1:.3g} and f1 score of {3:.2g}\"\\\n",
    "              .format(total_loss,total_correct,e+1, total_f1))\n",
    "            if (e % 10 == 0) and  train_validation:\n",
    "                train_losses.append(total_loss)\n",
    "                correct_val = 0\n",
    "                losses_val = []\n",
    "                f1s_val = []\n",
    "                val_indicies = np.arange(Xd_val.shape[0])\n",
    "                for j in range(int(math.ceil(Xd_val.shape[0]/batch_size))):\n",
    "                    start_idx = (j*batch_size)%Xd_val.shape[0]\n",
    "                    idx = val_indicies[start_idx:start_idx+batch_size]\n",
    "                    feed_dict_val = {X: Xd_val[idx, :],\n",
    "                                 y: yd_val[idx] }\n",
    "                    actual_batch_size = yd_val[idx].shape[0]\n",
    "                    val_loss, val_corr, y_out_val = sess.run([mean_loss, correct_prediction, y_out] ,feed_dict=feed_dict_val)\n",
    "                    losses_val.append(val_loss*actual_batch_size)\n",
    "                    correct_val += np.sum(val_corr)\n",
    "                    f1_score_val = calculate_average_F1_score(from_eight(onehot(y_out_val)), from_eight(yd_val[idx]))\n",
    "                    f1s_val.append(f1_score_val*actual_batch_size)\n",
    "                total_val_loss = np.sum(losses_val)/Xd_val.shape[0]\n",
    "                total_val_correct = correct_val/Xd_val.shape[0]\n",
    "                val_losses.append(total_val_loss)\n",
    "                val_f1 = np.sum(f1s_val)/Xd_val.shape[0]\n",
    "                print(\"Validation loss, Overall loss = {0:.3g}, accuracy of {1:.3g} and f1 score of {2:.3g}\".format(total_val_loss, total_val_correct, val_f1))        \n",
    "                plt.plot(losses)\n",
    "                plt.grid(True)\n",
    "                plt.title('Epoch {} Loss'.format(e+1))\n",
    "                plt.xlabel('minibatch number')\n",
    "                plt.ylabel('minibatch loss')\n",
    "                plt.show()\n",
    "                if total_val_loss < best_loss:\n",
    "                    best_loss = total_val_loss\n",
    "             #         output_dir = checkpoint_path + '/run-%02d%02d-%02d%02d' % tuple(localtime(time()))[1:5]\n",
    "                    output_dir = checkpoint_path\n",
    "                    if not gfile.Exists(output_dir):\n",
    "                        gfile.MakeDirs(output_dir)\n",
    "                    saver.save(sess, output_dir)\n",
    "                    print('Model saved in file : %s' % output_dir)             \n",
    "        plt.plot(train_losses)\n",
    "        plt.plot(val_losses)\n",
    "        plt.grid(True)\n",
    "        plt.title('Epoch {} Loss'.format(epoch_num))\n",
    "        plt.xlabel('epoch number')\n",
    "        plt.ylabel('epoch loss')\n",
    "        plt.show()                    \n",
    "        print('Training finished !')\n",
    "\n",
    "\n",
    "    if validation:\n",
    "        correct = 0\n",
    "        losses = []\n",
    "        f1s_val = []\n",
    "        val_indicies = np.arange(Xd_val.shape[0])\n",
    "        for j in range(int(math.ceil(Xd_val.shape[0]/batch_size))):\n",
    "            start_idx = (j*batch_size)%Xd_val.shape[0]\n",
    "            idx = val_indicies[start_idx:start_idx+batch_size]\n",
    "            feed_dict_val = {X: Xd_val[idx, :],\n",
    "                         y: yd_val[idx] }\n",
    "            actual_batch_size = yd_val[idx].shape[0]\n",
    "            loss, corr, y_out_val = sess.run([mean_loss, correct_prediction, y_out],feed_dict=feed_dict_val)\n",
    "            losses.append(loss*actual_batch_size)\n",
    "            correct += np.sum(corr)\n",
    "            f1_score_val = calculate_average_F1_score(from_eight(onehot(y_out_val)), from_eight(yd_val[idx]))\n",
    "            f1s_val.append(f1_score_val*actual_batch_size)\n",
    "        total_val_correct = correct/Xd_val.shape[0]\n",
    "        total_val_loss = np.sum(losses)/Xd_val.shape[0]\n",
    "        val_f1 = np.sum(f1s_val)/Xd_val.shape[0]\n",
    "        print(\"Validation loss, Overall loss = {0:.3g}, accuracy of {1:.3g} and f1 score of {2:.3g}\"\\\n",
    "          .format(total_val_loss,total_val_correct, val_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum(yd_val)/sum(sum(yd_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)\n",
    "plt.grid(True)\n",
    "plt.title('Epoch {} Loss'.format(epoch_num))\n",
    "plt.xlabel('epoch number')\n",
    "plt.ylabel('epoch loss')\n",
    "plt.show()                 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
